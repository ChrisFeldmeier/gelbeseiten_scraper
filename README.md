# Gelbe Seiten Scraper - Universal

Ein leistungsstarker Python-Scraper zum Extrahieren von Unternehmensdaten von Gelbe Seiten Deutschland.

## âœ¨ Features

âœ… **Beliebige Suchbegriffe** - Nicht nur Steuerberater! Scrapt Ã„rzte, AnwÃ¤lte, Restaurants, etc.  
âœ… Extrahiert **ALLE** verfÃ¼gbaren DatensÃ¤tze fÃ¼r jeden Suchbegriff  
âœ… VollstÃ¤ndige Kontaktdaten: Name, Adresse, PLZ, Stadt, Telefon  
âœ… **E-Mail-Adressen** (ca. 35% Erfolgsquote) ğŸ“§  
âœ… **Website-URLs** (ca. 95% Erfolgsquote) ğŸŒ  
âœ… **Firmenlogos** (ca. 82% Erfolgsquote) ğŸ–¼ï¸  
âœ… Bewertungen und Rezensionen â­  
âœ… Spezialisierungen und Beschreibungen  
âœ… Automatische Fortschrittsspeicherung alle 100 EintrÃ¤ge  
âœ… Robustes Error Handling  
âœ… Rate Limiting zum Schutz des Servers  

## ğŸ” UnterstÃ¼tzte Suchbegriffe

Der Scraper funktioniert mit **ALLEN** Kategorien auf Gelbe Seiten:
- `steuerberater` (38.902 EintrÃ¤ge)
- `Ã¤rzte` (Ã„rzte & ZahnÃ¤rzte)
- `rechtsanwÃ¤lte` (AnwÃ¤lte)
- `restaurants` (Gastronomie)
- `handwerker` (Handwerksbetriebe)
- `apotheken` (Apotheken)
- ... und viele mehr!

## ğŸ“Š Erfolgsquoten (basierend auf 500 Steuerberater-EintrÃ¤gen)

| Datenfeld | Erfolgsquote | Beschreibung |
|-----------|--------------|--------------|
| Name | 100% âœ… | Firmenname / Name |
| Adresse | 100% âœ… | StraÃŸe & Hausnummer |
| PLZ | 100% âœ… | Postleitzahl |
| Stadt | 100% âœ… | Stadt |
| Telefon | 100% âœ… | Telefonnummer |
| **E-Mail** | **35%** ğŸ“§ | E-Mail-Adresse |
| **Website** | **95%** ğŸŒ | Website-URL |
| **Logo** | **82%** ğŸ–¼ï¸ | Firmenlogo-URL |
| Bewertung | ~40% â­ | Bewertung (z.B. 5,0) |
| Review Count | ~40% ğŸ“ | Anzahl Bewertungen |
| Spezialisierung | ~80% ğŸ¯ | TÃ¤tigkeitsschwerpunkte |
| Beschreibung | ~20% ğŸ“„ | Kurzbeschreibung |
| Detail-URL | 100% ğŸ”— | Link zur Detailseite |

### Beispiel: Steuerberater (38.902 gesamt)
- Ca. **13.615** EintrÃ¤ge mit E-Mail-Adresse
- Ca. **36.957** EintrÃ¤ge mit Website
- Ca. **31.899** EintrÃ¤ge mit Firmenlogo
- Ca. **11.670** KOMPLETT-EintrÃ¤ge (mit E-Mail, Website & Logo)

## ğŸš€ Installation

```bash
pip3 install requests beautifulsoup4
```

## ğŸ’» Verwendung

### Interaktiver Modus (empfohlen)

```bash
python3 gelbeseiten_scraper.py
```

Dann wirst du gefragt:
1. **Suchbegriff**: Was mÃ¶chtest du scrapen? (z.B. "steuerberater", "Ã¤rzte", "restaurants")
2. **Modus**: Test (100), Full (alle), oder Custom

### Beispiel-Session:

```
ğŸ” SUCHBEGRIFF:
Was mÃ¶chtest du scrapen? [default: steuerberater]: Ã¤rzte
âœ Suche nach: 'Ã¤rzte'

ğŸ“Š SCRAPING-MODUS:
1. Test mode (first 100 results)
2. Full scrape (ALL results - may take hours)
3. Custom amount

Enter choice (1/2/3) [default: 1]: 1

âœ Test mode: Scraping first 100 results
```

### Programmatische Verwendung

```python
from gelbeseiten_scraper import GelbeSeitenScraperComplete

# Ã„rzte scrapen
scraper = GelbeSeitenScraperComplete(search_term="Ã¤rzte")
results = scraper.scrape_all(max_results=500)
scraper.export_to_csv("gelbeseiten_Ã¤rzte.csv")

# Restaurants scrapen
scraper = GelbeSeitenScraperComplete(search_term="restaurants")
results = scraper.scrape_all(max_results=1000)
scraper.export_to_csv("gelbeseiten_restaurants.csv")
```

## ğŸ“ Output

Die Daten werden automatisch in einer CSV-Datei mit dem Suchbegriff im Namen gespeichert:

```
gelbeseiten_steuerberater.csv
gelbeseiten_Ã¤rzte.csv
gelbeseiten_restaurants.csv
...
```

### CSV-Spalten:

```csv
name,address,postal_code,city,phone,email,website,logo_url,rating,review_count,specialties,description,detail_url
```

### Beispiel-Eintrag (Steuerberater):

```
Name: Steuerkanzlei Schubert Stefan
Adresse: Peterstr. 65, 90478 NÃ¼rnberg
Telefon: 0911 46 53 09
E-Mail: schubert@schubert-steuerkanzlei.de
Website: https://www.schubert-steuerkanzlei.de/
Logo: https://ies.v4all.de/0122/GS/0122/1/5711/32755711_maxhoehe_100.jpg
Rating: 5,0 (122 Bewertungen)
```

### Beispiel-Eintrag (Ã„rzte):

```
Name: Dr. med. Grit Weigel
Adresse: Schoppershofstr. 35, 90489 NÃ¼rnberg
Telefon: 0911 2 42 78 85
Website: https://www.dr-weigel.de
Logo: https://example.com/logo.jpg
```

## ğŸ¯ Features im Detail

### ğŸ“§ E-Mail-Extraktion
E-Mails werden aus versteckten JSON-Daten im Chat-Button extrahiert:
```html
<button data-parameters='{"inboxConfig":{"organizationQuery":{"generic":{"email":"info@example.de"}}}}'>
```
Nicht alle EintrÃ¤ge haben diese Funktion aktiviert â†’ **~35% Erfolgsquote**

### ğŸŒ Website-Extraktion
Website-URLs sind Base64-encodiert im HTML:
```html
<span data-webseitelink="aHR0cHM6Ly93d3cuZXhhbXBsZS5kZQ==">
```
Fast alle EintrÃ¤ge haben Websites â†’ **~95% Erfolgsquote**

### ğŸ–¼ï¸ Logo-Extraktion
Firmenlogos sind direkt als Bild-URLs verfÃ¼gbar:
```html
<img class="mod-Treffer__logo" src="https://example.com/logo.jpg">
```
Viele EintrÃ¤ge haben Logos â†’ **~82% Erfolgsquote**

### ğŸ’¾ Automatische Fortschrittsspeicherung
Der Scraper speichert automatisch alle 100 EintrÃ¤ge den aktuellen Stand. Bei Abbruch gehen keine Daten verloren.

### ğŸ›¡ï¸ Rate Limiting
- 1 Sekunde Pause zwischen Requests
- 3 Fehlversuche bei Problemen
- Respektvoller Umgang mit dem Server

### ğŸ” Error Handling
- Robustes Parsing mit Fallback-Optionen
- Detailliertes Logging aller AktivitÃ¤ten
- Automatische Wiederholung bei temporÃ¤ren Fehlern

### âœ¨ DatenqualitÃ¤t
- Alle Felder werden sauber extrahiert
- Keine doppelten EintrÃ¤ge
- UTF-8 Encoding fÃ¼r korrekte Umlaute

## âš¡ Performance

| Modus | Anzahl | Dauer |
|-------|--------|-------|
| Test | 100 EintrÃ¤ge | ~15 Sekunden |
| Medium | 500 EintrÃ¤ge | ~8-10 Minuten |
| Large | 5.000 EintrÃ¤ge | ~1,5 Stunden |
| Full (Steuerberater) | 38.902 EintrÃ¤ge | ~11 Stunden |

**Rate**: ~10 EintrÃ¤ge pro Sekunde mit Pausen

## ğŸ“Š Beispiel-Statistiken

### Steuerberater (500 EintrÃ¤ge):
```
Total entries scraped: 500
Entries with email: 175 (35.0%)
Entries with website: 473 (94.6%)
Entries with logo: 410 (82.0%)
Complete entries: 150 (30.0%)
```

### Ã„rzte (100 EintrÃ¤ge):
```
Total entries scraped: 100
Entries with email: 38 (38.0%)
Entries with website: 94 (94.0%)
Entries with logo: 78 (78.0%)
```

## ğŸ”§ Technische Details

### Funktionsweise

1. **Suchbegriff-Eingabe**: Benutzer gibt gewÃ¼nschte Kategorie ein
2. **Session Initialisierung**: Cookies und Headers fÃ¼r `/suche/{suchbegriff}/bundesweit`
3. **AJAX Requests**: Pagination Ã¼ber `/ajaxsuche` Endpoint mit `WAS={suchbegriff}`
4. **JSON Parsing**: Response enthÃ¤lt HTML als JSON-Field
5. **HTML Parsing**: BeautifulSoup extrahiert strukturierte Daten
6. **E-Mail Extraktion**: Aus Chat-Button JSON-Daten
7. **Website Extraktion**: Base64-Decoding der Website-URLs
8. **Logo Extraktion**: Direkte Bild-URLs
9. **CSV Export**: Strukturierte Ausgabe mit Suchbegriff im Dateinamen

### Systemanforderungen

- Python 3.6+
- requests
- beautifulsoup4
- Internetverbindung
- ~150 KB Speicherplatz pro 500 EintrÃ¤ge

## ğŸ“ Erweiterte Verwendung

### Verschiedene Branchen scrapen

```python
from gelbeseiten_scraper import GelbeSeitenScraperComplete

# Verschiedene Branchen
search_terms = ["steuerberater", "Ã¤rzte", "rechtsanwÃ¤lte", "restaurants"]

for term in search_terms:
    scraper = GelbeSeitenScraperComplete(search_term=term)
    results = scraper.scrape_all(max_results=500)
    scraper.export_to_csv(f"gelbeseiten_{term}.csv")
    print(f"âœ“ {term}: {len(results)} EintrÃ¤ge gespeichert")
```

### Mit Fortschrittsspeicherung

```python
scraper = GelbeSeitenScraperComplete(search_term="steuerberater")

# Scrape mit automatischer Zwischenspeicherung
results = scraper.scrape_all(
    max_results=None,  # Alle EintrÃ¤ge
    results_per_page=10,
    output_file="steuerberater_full.csv"  # Speichert alle 100 EintrÃ¤ge
)
```

## âš ï¸ Datenschutz & Rechtliches

**WICHTIG**: 
- Nur Ã¶ffentlich verfÃ¼gbare Daten werden gesammelt
- Respektiere die robots.txt und Terms of Service
- Verwende die Daten nur fÃ¼r rechtmÃ¤ÃŸige Zwecke
- Kommerzielle Nutzung eventuell eingeschrÃ¤nkt
- Rate Limiting zum Schutz des Servers implementiert

## ğŸ› Troubleshooting

### Problem: Keine E-Mails werden extrahiert
**LÃ¶sung**: E-Mails sind nur fÃ¼r ~35% der EintrÃ¤ge verfÃ¼gbar. Das ist normal.

### Problem: Scraper stoppt vorzeitig
**LÃ¶sung**: PrÃ¼fe deine Internetverbindung. Der Scraper speichert den Fortschritt automatisch alle 100 EintrÃ¤ge.

### Problem: "Too many consecutive failures"
**LÃ¶sung**: Server kÃ¶nnte temporÃ¤r nicht erreichbar sein. Warte einige Minuten und versuche es erneut.

### Problem: Suchbegriff findet keine Ergebnisse
**LÃ¶sung**: Stelle sicher, dass der Suchbegriff auf Gelbe Seiten existiert. Teste zuerst manuell auf der Website: `https://www.gelbeseiten.de/suche/{dein_begriff}/bundesweit`

### Problem: Umlaute im Dateinamen
**LÃ¶sung**: Der Scraper erstellt automatisch sichere Dateinamen. `Ã¤rzte` wird zu `gelbeseiten_Ã¤rzte.csv`

## ğŸ“¦ Projektstruktur

```
gelbeseiten/
â”œâ”€â”€ gelbeseiten_scraper.py  # Haupt-Scraper (universal)
â”œâ”€â”€ gelbeseiten.csv         # Steuerberater (500 EintrÃ¤ge)
â””â”€â”€ README.md                         # Diese Dokumentation
```

## ğŸ“ Beispiel-Output

```
================================================================================
SCRAPING STATISTICS
================================================================================
Total entries scraped: 500
Entries with email: 175 (35.0%)
Entries with website: 473 (94.6%)
Entries with logo: 410 (82.0%)
Output file: gelbeseiten_steuerberater.csv
================================================================================
```

## ğŸ’¡ Use Cases

### Business Development
```bash
# Alle Steuerberater in Deutschland
python3 gelbeseiten_scraper.py
> steuerberater
> Option 2 (Full scrape)
```

### Marketing Recherche
```bash
# 1000 Restaurants fÃ¼r Marketing-Kampagne
python3 gelbeseiten_scraper.py
> restaurants
> Option 3 (Custom)
> 1000
```

### Wettbewerbsanalyse
```bash
# Alle Konkurrenten in deiner Branche
python3 gelbeseiten_scraper.py
> deine_branche
> Option 2 (Full scrape)
```

## ğŸ¤ UnterstÃ¼tzung

Bei Fragen oder Problemen, prÃ¼fe zuerst:
1. âœ… Sind `requests` und `beautifulsoup4` installiert?
2. âœ… Funktioniert deine Internetverbindung?
3. âœ… Existiert dein Suchbegriff auf Gelbe Seiten?
4. âœ… Sind die Log-Meldungen hilfreich?

## ğŸ“œ Version History

- **v3.1 (Universal)** - Variable Suchbegriffe hinzugefÃ¼gt
- **v3.0 (Complete)** - Website & Logo Extraktion hinzugefÃ¼gt
- **v2.0** - Verbesserte E-Mail-Extraktion aus Chat-Daten
- **v1.0** - Basis-Scraper mit Pagination

---

## ğŸš€ Quick Start

```bash
# Installation
pip3 install requests beautifulsoup4

# Scraper starten
python3 gelbeseiten_scraper.py

# Eingaben:
1. Suchbegriff eingeben (z.B. "steuerberater")
2. Modus wÃ¤hlen (1=Test, 2=Full, 3=Custom)
3. Warten und CSV-Datei erhalten!
```

**Viel Erfolg beim Scrapen! ğŸš€**

*Letztes Update: November 2025*
